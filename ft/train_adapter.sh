#!/bin/bash

# Fine-tuning script using Axolotl
# Make sure you have axolotl installed: pip install axolotl

echo "ğŸš€ Starting fine-tuning with Axolotl..."

# Move to ft directory
cd "$(dirname "$0")"

# Check if virtual environment is activated
if [[ "$VIRTUAL_ENV" != "" ]]; then
    echo "âœ… Virtual environment detected: $VIRTUAL_ENV"
else
    echo "âš ï¸  Warning: No virtual environment detected. Activating..."
    source ../venv/bin/activate
fi

# Check if axolotl is installed
if ! python -c "import axolotl" &> /dev/null; then
    echo "ğŸ”§ Axolotl not found. Installing..."
    pip install axolotl[flash-attn]
fi

# Check if required dependencies are installed
echo "ğŸ“¦ Checking dependencies..."
pip install accelerate transformers torch datasets

# Check if CUDA is available
if command -v nvidia-smi &> /dev/null; then
    echo "ğŸš€ CUDA detected. Running with GPU acceleration."
    export ACCELERATE_USE_CUDA=1
else
    echo "ğŸ’» No CUDA detected. Running on CPU (this will be slow)."
    export ACCELERATE_USE_CUDA=0
fi

# Generate training data from ingested repositories
echo "ğŸ“Š Generating training data from repositories..."
python generate_training_data.py

# Verify training data exists
if [ ! -f "sft.jsonl" ]; then
    echo "âŒ Training data not found. Running basic data generation..."
    python build_sft_data.py
fi

# Initialize accelerate if not already done
echo "âš™ï¸  Initializing accelerate configuration..."
accelerate config default

# Run the training
echo "ğŸ‹ï¸  Starting training..."
accelerate launch -m axolotl.cli.train axolotl.yaml

echo "âœ… Training completed!"
echo "ğŸ“ Model saved to ./out/"

# Optional: Convert to HuggingFace format
echo "ğŸ”„ Converting to HuggingFace format..."
python -m axolotl.cli.merge_lora axolotl.yaml --lora_model_dir="./out"

echo "ğŸ‰ Fine-tuning process complete!"
echo "ğŸ“ Fine-tuned model available at: ./out/"